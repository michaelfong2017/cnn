{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.2.0 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from tensorflow==2.2.0) (1.36.1)\n",
      "Requirement already satisfied: scipy==1.4.1 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from tensorflow==2.2.0) (1.4.1)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from tensorflow==2.2.0) (3.15.6)\n",
      "Requirement already satisfied: astunparse==1.6.3 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from tensorflow==2.2.0) (1.6.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from tensorflow==2.2.0) (1.20.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from tensorflow==2.2.0) (3.3.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from tensorflow==2.2.0) (0.36.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from tensorflow==2.2.0) (1.12.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from tensorflow==2.2.0) (1.1.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from tensorflow==2.2.0) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from tensorflow==2.2.0) (1.1.0)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from tensorflow==2.2.0) (0.3.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from tensorflow==2.2.0) (2.2.0)\n",
      "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from tensorflow==2.2.0) (2.2.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from tensorflow==2.2.0) (0.12.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from tensorflow==2.2.0) (0.2.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from tensorflow==2.2.0) (2.10.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.8.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.27.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.25.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.3.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.7.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.26.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.7.4.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (0.24.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from scikit-learn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from scikit-learn) (1.20.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from scikit-learn) (1.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (3.3.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from matplotlib) (8.1.2)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from matplotlib) (1.20.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: imutils in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (0.5.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (4.5.1.48)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from opencv-python) (1.20.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: wget in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: kaggle in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (1.5.10)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from kaggle) (1.26.3)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from kaggle) (1.15.0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from kaggle) (4.0.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from kaggle) (2020.12.5)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from kaggle) (2.8.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from kaggle) (4.59.0)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from kaggle) (2.25.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from requests->kaggle) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\user\\anaconda3\\envs\\cnn_env\\lib\\site-packages (from requests->kaggle) (4.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow==2.2.0\n",
    "%pip install scikit-learn\n",
    "%pip install matplotlib\n",
    "%pip install imutils\n",
    "%pip install opencv-python\n",
    "%pip install wget\n",
    "%pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [........................................................................] 93427475 / 93427475"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "url = 'https://s3-us-west-2.amazonaws.com/static.pyimagesearch.com/keras-fine-tune-resnet/fine-tune-resnet.zip'\n",
    "filename = wget.download(url, './') # second argument is the directory to save, default is \".\"\n",
    "from zipfile import ZipFile\n",
    "with ZipFile(filename, 'r') as zip_ref:\n",
    "    zip_ref.extractall('.') # argument is the directory to extract_to, default is \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Documents\\cnn\\fine-tune-resnet\\fine-tune-resnet\n"
     ]
    }
   ],
   "source": [
    "%cd fine-tune-resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle\n",
    "kaggle.api.authenticate()\n",
    "kaggle.api.dataset_download_files('imneonizer/normal-vs-camouflage-clothes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile('normal-vs-camouflage-clothes.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import classification_report\n",
    "from matplotlib import pyplot as plt\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_imshow(title, image):\n",
    "\t# convert the image frame BGR to RGB color space and display it\n",
    "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\tplt.imshow(image)\n",
    "\tplt.title(title)\n",
    "\tplt.grid(False)\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # initialize the path to the *original* input directory of images\n",
    "    ORIG_INPUT_DATASET = \"8k_normal_vs_camouflage_clothes_images\"\n",
    "\n",
    "    # initialize the base path to the *new* directory that will contain\n",
    "    # our images after computing the training and testing split\n",
    "    BASE_PATH = \"camo_not_camo\"\n",
    "\n",
    "    # derive the training, validation, and testing directories\n",
    "    TRAIN_PATH = os.path.sep.join([BASE_PATH, \"training\"])\n",
    "    VAL_PATH = os.path.sep.join([BASE_PATH, \"validation\"])\n",
    "    TEST_PATH = os.path.sep.join([BASE_PATH, \"testing\"])\n",
    "\n",
    "    # define the amount of data that will be used training\n",
    "    TRAIN_SPLIT = 0.75\n",
    "\n",
    "    # the amount of validation data will be a percentage of the\n",
    "    # *training* data\n",
    "    VAL_SPLIT = 0.1\n",
    "\n",
    "    # define the names of the classes\n",
    "    CLASSES = [\"camouflage_clothes\", \"normal_clothes\"]\n",
    "\n",
    "    # initialize the initial learning rate, batch size, and number of\n",
    "    # epochs to train for\n",
    "    INIT_LR = 1e-4\n",
    "    BS = 32\n",
    "    NUM_EPOCHS = 20\n",
    "\n",
    "    # define the path to checkpoints\n",
    "    CHECKPOINT_PATH = os.path.sep.join([\"output\", \"checkpoint\"])\n",
    "    \n",
    "    # define the path to the serialized output model after training\n",
    "    MODEL_PATH = os.path.sep.join([\"output\", \"model\"])\n",
    "    \n",
    "    # define the path to training history\n",
    "    HISTORY_PATH = os.path.sep.join([\"output\", \"history\"])\n",
    "\n",
    "# instantiate a Config object\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the paths to all input images in the original input directory\n",
    "# and shuffle them\n",
    "imagePaths = list(paths.list_images(config.ORIG_INPUT_DATASET))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "# compute the training and testing split\n",
    "i = int(len(imagePaths) * config.TRAIN_SPLIT)\n",
    "trainPaths = imagePaths[:i]\n",
    "testPaths = imagePaths[i:]\n",
    "\n",
    "# we'll be using part of the training data for validation\n",
    "i = int(len(trainPaths) * config.VAL_SPLIT)\n",
    "valPaths = trainPaths[:i]\n",
    "trainPaths = trainPaths[i:]\n",
    "\n",
    "# define the datasets that we'll be building\n",
    "datasets = [\n",
    "\t(\"training\", trainPaths, config.TRAIN_PATH),\n",
    "\t(\"validation\", valPaths, config.VAL_PATH),\n",
    "\t(\"testing\", testPaths, config.TEST_PATH)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the datasets\n",
    "for (dType, imagePaths, baseOutput) in datasets:\n",
    "\t# show which data split we are creating\n",
    "\tprint(\"[INFO] building '{}' split\".format(dType))\n",
    "\n",
    "\t# if the output base output directory does not exist, create it\n",
    "\tif not os.path.exists(baseOutput):\n",
    "\t\tprint(\"[INFO] 'creating {}' directory\".format(baseOutput))\n",
    "\t\tos.makedirs(baseOutput)\n",
    "\n",
    "\t# loop over the input image paths\n",
    "\tfor inputPath in imagePaths:\n",
    "\t\t# extract the filename of the input image along with its\n",
    "\t\t# corresponding class label\n",
    "\t\tfilename = inputPath.split(os.path.sep)[-1]\n",
    "\t\tlabel = inputPath.split(os.path.sep)[-2]\n",
    "\n",
    "\t\t# build the path to the label directory\n",
    "\t\tlabelPath = os.path.sep.join([baseOutput, label])\n",
    "\n",
    "\t\t# if the label output directory does not exist, create it\n",
    "\t\tif not os.path.exists(labelPath):\n",
    "\t\t\tprint(\"[INFO] 'creating {}' directory\".format(labelPath))\n",
    "\t\t\tos.makedirs(labelPath)\n",
    "\n",
    "\t\t# construct the path to the destination image and then copy\n",
    "\t\t# the image itself\n",
    "\t\tp = os.path.sep.join([labelPath, filename])\n",
    "\t\tshutil.copy2(inputPath, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the argument parser and parse the arguments\n",
    "#ap = argparse.ArgumentParser()\n",
    "#ap.add_argument(\"-p\", \"--plot\", type=str, default=\"plot.png\",\n",
    "#\thelp=\"path to output loss/accuracy plot\")\n",
    "#args = vars(ap.parse_args())\n",
    "\n",
    "# since we are using Jupyter Notebooks we can replace our argument\n",
    "# parsing code with *hard coded* arguments and values\n",
    "args = {\n",
    "\t\"plot\": \"plot.png\"\n",
    "}\n",
    "\n",
    "# determine the total number of image paths in training, validation,\n",
    "# and testing directories\n",
    "totalTrain = len(list(paths.list_images(config.TRAIN_PATH)))\n",
    "totalVal = len(list(paths.list_images(config.VAL_PATH)))\n",
    "totalTest = len(list(paths.list_images(config.TEST_PATH)))\n",
    "print(list(paths.list_images(config.VAL_PATH)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the training training data augmentation object\n",
    "trainAug = ImageDataGenerator(\n",
    "\trotation_range=25,\n",
    "\tzoom_range=0.1,\n",
    "\twidth_shift_range=0.1,\n",
    "\theight_shift_range=0.1,\n",
    "\tshear_range=0.2,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")\n",
    "\n",
    "# initialize the validation/testing data augmentation object (which\n",
    "# we'll be adding mean subtraction to)\n",
    "valAug = ImageDataGenerator()\n",
    "\n",
    "# define the ImageNet mean subtraction (in RGB order) and set the\n",
    "# the mean subtraction value for each of the data augmentation\n",
    "# objects\n",
    "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
    "trainAug.mean = mean\n",
    "valAug.mean = mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the training generator\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "\tconfig.TRAIN_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(224, 224),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=True,\n",
    "\tbatch_size=config.BS)\n",
    "\n",
    "# initialize the validation generator\n",
    "valGen = valAug.flow_from_directory(\n",
    "\tconfig.VAL_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(224, 224),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=config.BS)\n",
    "\n",
    "# initialize the testing generator\n",
    "testGen = valAug.flow_from_directory(\n",
    "\tconfig.TEST_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(224, 224),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=config.BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the ResNet-50 network, ensuring the head FC layer sets are left\n",
    "# off\n",
    "print(\"[INFO] preparing model...\")\n",
    "baseModel = ResNet50(weights=\"imagenet\", include_top=False,\n",
    "\tinput_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "# construct the head of the model that will be placed on top of the\n",
    "# the base model\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(256, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(len(config.CLASSES), activation=\"softmax\")(headModel)\n",
    "\n",
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "# loop over all layers in the base model and freeze them so they will\n",
    "# *not* be updated during the training process\n",
    "for layer in baseModel.layers:\n",
    "\tlayer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "model_checkpoint_callback = ModelCheckpoint(os.path.sep.join([config.CHECKPOINT_PATH, filepath]), monitor='val_accuracy',verbose=1, \n",
    "                            save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "opt = Adam(lr=config.INIT_LR, decay=config.INIT_LR / config.NUM_EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "history = model.fit(\n",
    "\ttrainGen,\n",
    "\tsteps_per_epoch=totalTrain // config.BS,\n",
    "\tvalidation_data=valGen,\n",
    "\tvalidation_steps=totalVal // config.BS,\n",
    "\tepochs=config.NUM_EPOCHS,\n",
    "    callbacks=[model_checkpoint_callback],\n",
    "    initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize the model to disk\n",
    "print(\"[INFO] saving model...\")\n",
    "model.save(config.MODEL_PATH, save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class History_trained_model(object):\n",
    "    def __init__(self, history, epoch, params):\n",
    "        self.history = history\n",
    "        self.epoch = epoch\n",
    "        self.params = params\n",
    "with open(os.path.sep.join([config.HISTORY_PATH, \"train_history_dict\"]), 'wb') as file_pi:\n",
    "    model_history= History_trained_model(history.history, history.epoch, history.params)\n",
    "    pickle.dump(model_history, file_pi, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is for loading and using models and history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = load_model(os.path.sep.join([config.CHECKPOINT_PATH, 'weights-improvement-01-0.99.hdf5']))\n",
    "# new_model = load_model(config.MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "def load_image(img_path, show=False):\n",
    "\n",
    "    img = load_img(img_path, target_size=(224, 224))\n",
    "    img_tensor = img_to_array(img)                    # (height, width, channels)\n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
    "    # img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n",
    "\n",
    "    if show:\n",
    "        plt.imshow(img_tensor[0])                           \n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return img_tensor\n",
    "\n",
    "\n",
    "# load the image\n",
    "image_path = os.path.sep.join([config.BASE_PATH, \"testing\", \"normal_clothes\", \"0001259.jpg\"])\n",
    "img = load_image(image_path)\n",
    "my_predIdxs = new_model.predict(img)\n",
    "print(my_predIdxs)\n",
    "print(np.argmax(my_predIdxs, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.sep.join([config.HISTORY_PATH, \"train_history_dict\"]), 'rb') as file_pi:\n",
    "    new_history = pickle.load(file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn_env",
   "language": "python",
   "name": "cnn_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
